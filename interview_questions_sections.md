# PySpark Interview Questions

## 1. Production Deployment
**Question:** **How would you package, configure, and deploy PySpark jobs for production use?**

---

## 2. Observability Setup
**Question:** **What's your strategy for setting up efficient logging, alerting, and monitoring for PySpark pipelines?**

---

## 3. Resource Tuning
**Question:** **How do you tune Spark executors, memory, and partitions to ensure balanced resource usage?**

---

## 4. Transaction Aggregation
**Question:** **Write a PySpark job that aggregates daily transactions per customer from a large dataset.**

---

## 5. Data Quality Management
**Question:** **How do you clean, impute, and validate inconsistent or incomplete data in PySpark DataFrames?**

---

## 6. JSON Flattening
**Question:** **What's your method to flatten multi-level nested JSON files into a relational format using PySpark?**

---

## 7. Data Skew Resolution
**Question:** **If your PySpark transformation suffers from data skew, how do you detect and fix it?**

---

## 8. Join Optimization
**Question:** **When large joins lead to memory pressure, what optimization techniques would you apply?**

---

## 9. Real-Time Streaming Pipeline
**Question:** **Describe how you'd build a PySpark + Kafka pipeline to handle near real-time streaming data.**

---

## 10. Anomaly Detection in Streams
**Question:** **How would you detect unusual behavior in IoT or sensor streams using PySpark Structured Streaming?**

---

## 11. Cross-Platform ETL Orchestration
**Question:** **How would you orchestrate a PySpark-based ETL job that extracts from SQL Server and loads into Snowflake?**

---

## 12. Mixed-Format Data Processing
**Question:** **What's your approach to reading and transforming mixed-format data (CSV, Parquet, and JSON) in PySpark?**

---

## 13. REST API Integration
**Question:** **How do you merge external REST API data into your PySpark pipeline efficiently?**

---

## 14. Multi-Source Data Joining
**Question:** **How would you join data coming from Hive tables and Kafka topics in a single PySpark job?**

---

## 15. Schema Evolution Handling
**Question:** **Describe how you'd handle schema evolution in streaming data with PySpark.**
